<!DOCTYPE html>
<HTML lang = "en">
<HEAD>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>AR(p) auto-correlated trials with LMMs</title>
  

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: { equationNumbers: { autoNumber: "AMS" } }
    });
  </script>

  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>

  
<style>
pre.hljl {
    border: 1px solid #ccc;
    margin: 5px;
    padding: 5px;
    overflow-x: auto;
    color: rgb(68,68,68); background-color: rgb(251,251,251); }
pre.hljl > span.hljl-t { }
pre.hljl > span.hljl-w { }
pre.hljl > span.hljl-e { }
pre.hljl > span.hljl-eB { }
pre.hljl > span.hljl-o { }
pre.hljl > span.hljl-k { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kc { color: rgb(59,151,46); font-style: italic; }
pre.hljl > span.hljl-kd { color: rgb(214,102,97); font-style: italic; }
pre.hljl > span.hljl-kn { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kp { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kr { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-kt { color: rgb(148,91,176); font-weight: bold; }
pre.hljl > span.hljl-n { }
pre.hljl > span.hljl-na { }
pre.hljl > span.hljl-nb { }
pre.hljl > span.hljl-nbp { }
pre.hljl > span.hljl-nc { }
pre.hljl > span.hljl-ncB { }
pre.hljl > span.hljl-nd { color: rgb(214,102,97); }
pre.hljl > span.hljl-ne { }
pre.hljl > span.hljl-neB { }
pre.hljl > span.hljl-nf { color: rgb(66,102,213); }
pre.hljl > span.hljl-nfm { color: rgb(66,102,213); }
pre.hljl > span.hljl-np { }
pre.hljl > span.hljl-nl { }
pre.hljl > span.hljl-nn { }
pre.hljl > span.hljl-no { }
pre.hljl > span.hljl-nt { }
pre.hljl > span.hljl-nv { }
pre.hljl > span.hljl-nvc { }
pre.hljl > span.hljl-nvg { }
pre.hljl > span.hljl-nvi { }
pre.hljl > span.hljl-nvm { }
pre.hljl > span.hljl-l { }
pre.hljl > span.hljl-ld { color: rgb(148,91,176); font-style: italic; }
pre.hljl > span.hljl-s { color: rgb(201,61,57); }
pre.hljl > span.hljl-sa { color: rgb(201,61,57); }
pre.hljl > span.hljl-sb { color: rgb(201,61,57); }
pre.hljl > span.hljl-sc { color: rgb(201,61,57); }
pre.hljl > span.hljl-sd { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdB { color: rgb(201,61,57); }
pre.hljl > span.hljl-sdC { color: rgb(201,61,57); }
pre.hljl > span.hljl-se { color: rgb(59,151,46); }
pre.hljl > span.hljl-sh { color: rgb(201,61,57); }
pre.hljl > span.hljl-si { }
pre.hljl > span.hljl-so { color: rgb(201,61,57); }
pre.hljl > span.hljl-sr { color: rgb(201,61,57); }
pre.hljl > span.hljl-ss { color: rgb(201,61,57); }
pre.hljl > span.hljl-ssB { color: rgb(201,61,57); }
pre.hljl > span.hljl-nB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nbB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nfB { color: rgb(59,151,46); }
pre.hljl > span.hljl-nh { color: rgb(59,151,46); }
pre.hljl > span.hljl-ni { color: rgb(59,151,46); }
pre.hljl > span.hljl-nil { color: rgb(59,151,46); }
pre.hljl > span.hljl-noB { color: rgb(59,151,46); }
pre.hljl > span.hljl-oB { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-ow { color: rgb(102,102,102); font-weight: bold; }
pre.hljl > span.hljl-p { }
pre.hljl > span.hljl-c { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-ch { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cm { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cp { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cpB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-cs { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-csB { color: rgb(153,153,119); font-style: italic; }
pre.hljl > span.hljl-g { }
pre.hljl > span.hljl-gd { }
pre.hljl > span.hljl-ge { }
pre.hljl > span.hljl-geB { }
pre.hljl > span.hljl-gh { }
pre.hljl > span.hljl-gi { }
pre.hljl > span.hljl-go { }
pre.hljl > span.hljl-gp { }
pre.hljl > span.hljl-gs { }
pre.hljl > span.hljl-gsB { }
pre.hljl > span.hljl-gt { }
</style>



  <style type="text/css">
  @font-face {
  font-style: normal;
  font-weight: 300;
}
@font-face {
  font-style: normal;
  font-weight: 400;
}
@font-face {
  font-style: normal;
  font-weight: 600;
}
html {
  font-family: sans-serif; /* 1 */
  -ms-text-size-adjust: 100%; /* 2 */
  -webkit-text-size-adjust: 100%; /* 2 */
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block; /* 1 */
  vertical-align: baseline; /* 2 */
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  -moz-box-sizing: content-box;
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit; /* 1 */
  font: inherit; /* 2 */
  margin: 0; /* 3 */
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button; /* 2 */
  cursor: pointer; /* 3 */
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box; /* 1 */
  padding: 0; /* 2 */
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield; /* 1 */
  -moz-box-sizing: content-box;
  -webkit-box-sizing: content-box; /* 2 */
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0; /* 1 */
  padding: 0; /* 2 */
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  font-family: monospace, monospace;
  font-size : 0.8em;
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
thead th {
    border-bottom: 1px solid black;
    background-color: white;
}
tr:nth-child(odd){
  background-color: rgb(248,248,248);
}


/*
* Skeleton V2.0.4
* Copyright 2014, Dave Gamache
* www.getskeleton.com
* Free to use under the MIT license.
* http://www.opensource.org/licenses/mit-license.php
* 12/29/2014
*/
.container {
  position: relative;
  width: 100%;
  max-width: 960px;
  margin: 0 auto;
  padding: 0 20px;
  box-sizing: border-box; }
.column,
.columns {
  width: 100%;
  float: left;
  box-sizing: border-box; }
@media (min-width: 400px) {
  .container {
    width: 85%;
    padding: 0; }
}
@media (min-width: 550px) {
  .container {
    width: 80%; }
  .column,
  .columns {
    margin-left: 4%; }
  .column:first-child,
  .columns:first-child {
    margin-left: 0; }

  .one.column,
  .one.columns                    { width: 4.66666666667%; }
  .two.columns                    { width: 13.3333333333%; }
  .three.columns                  { width: 22%;            }
  .four.columns                   { width: 30.6666666667%; }
  .five.columns                   { width: 39.3333333333%; }
  .six.columns                    { width: 48%;            }
  .seven.columns                  { width: 56.6666666667%; }
  .eight.columns                  { width: 65.3333333333%; }
  .nine.columns                   { width: 74.0%;          }
  .ten.columns                    { width: 82.6666666667%; }
  .eleven.columns                 { width: 91.3333333333%; }
  .twelve.columns                 { width: 100%; margin-left: 0; }

  .one-third.column               { width: 30.6666666667%; }
  .two-thirds.column              { width: 65.3333333333%; }

  .one-half.column                { width: 48%; }

  /* Offsets */
  .offset-by-one.column,
  .offset-by-one.columns          { margin-left: 8.66666666667%; }
  .offset-by-two.column,
  .offset-by-two.columns          { margin-left: 17.3333333333%; }
  .offset-by-three.column,
  .offset-by-three.columns        { margin-left: 26%;            }
  .offset-by-four.column,
  .offset-by-four.columns         { margin-left: 34.6666666667%; }
  .offset-by-five.column,
  .offset-by-five.columns         { margin-left: 43.3333333333%; }
  .offset-by-six.column,
  .offset-by-six.columns          { margin-left: 52%;            }
  .offset-by-seven.column,
  .offset-by-seven.columns        { margin-left: 60.6666666667%; }
  .offset-by-eight.column,
  .offset-by-eight.columns        { margin-left: 69.3333333333%; }
  .offset-by-nine.column,
  .offset-by-nine.columns         { margin-left: 78.0%;          }
  .offset-by-ten.column,
  .offset-by-ten.columns          { margin-left: 86.6666666667%; }
  .offset-by-eleven.column,
  .offset-by-eleven.columns       { margin-left: 95.3333333333%; }

  .offset-by-one-third.column,
  .offset-by-one-third.columns    { margin-left: 34.6666666667%; }
  .offset-by-two-thirds.column,
  .offset-by-two-thirds.columns   { margin-left: 69.3333333333%; }

  .offset-by-one-half.column,
  .offset-by-one-half.columns     { margin-left: 52%; }

}
html {
  font-size: 62.5%; }
body {
  font-size: 1.5em; /* currently ems cause chrome bug misinterpreting rems on body element */
  line-height: 1.6;
  font-weight: 400;
  font-family: "Raleway", "HelveticaNeue", "Helvetica Neue", Helvetica, Arial, sans-serif;
  color: #222; }
h1, h2, h3, h4, h5, h6 {
  margin-top: 0;
  margin-bottom: 2rem;
  font-weight: 300; }
h1 { font-size: 3.6rem; line-height: 1.2;  letter-spacing: -.1rem;}
h2 { font-size: 3.4rem; line-height: 1.25; letter-spacing: -.1rem; }
h3 { font-size: 3.2rem; line-height: 1.3;  letter-spacing: -.1rem; }
h4 { font-size: 2.8rem; line-height: 1.35; letter-spacing: -.08rem; }
h5 { font-size: 2.4rem; line-height: 1.5;  letter-spacing: -.05rem; }
h6 { font-size: 1.5rem; line-height: 1.6;  letter-spacing: 0; }

p {
  margin-top: 0; }
a {
  color: #1EAEDB; }
a:hover {
  color: #0FA0CE; }
.button,
button,
input[type="submit"],
input[type="reset"],
input[type="button"] {
  display: inline-block;
  height: 38px;
  padding: 0 30px;
  color: #555;
  text-align: center;
  font-size: 11px;
  font-weight: 600;
  line-height: 38px;
  letter-spacing: .1rem;
  text-transform: uppercase;
  text-decoration: none;
  white-space: nowrap;
  background-color: transparent;
  border-radius: 4px;
  border: 1px solid #bbb;
  cursor: pointer;
  box-sizing: border-box; }
.button:hover,
button:hover,
input[type="submit"]:hover,
input[type="reset"]:hover,
input[type="button"]:hover,
.button:focus,
button:focus,
input[type="submit"]:focus,
input[type="reset"]:focus,
input[type="button"]:focus {
  color: #333;
  border-color: #888;
  outline: 0; }
.button.button-primary,
button.button-primary,
input[type="submit"].button-primary,
input[type="reset"].button-primary,
input[type="button"].button-primary {
  color: #FFF;
  background-color: #33C3F0;
  border-color: #33C3F0; }
.button.button-primary:hover,
button.button-primary:hover,
input[type="submit"].button-primary:hover,
input[type="reset"].button-primary:hover,
input[type="button"].button-primary:hover,
.button.button-primary:focus,
button.button-primary:focus,
input[type="submit"].button-primary:focus,
input[type="reset"].button-primary:focus,
input[type="button"].button-primary:focus {
  color: #FFF;
  background-color: #1EAEDB;
  border-color: #1EAEDB; }
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea,
select {
  height: 38px;
  padding: 6px 10px; /* The 6px vertically centers text on FF, ignored by Webkit */
  background-color: #fff;
  border: 1px solid #D1D1D1;
  border-radius: 4px;
  box-shadow: none;
  box-sizing: border-box; }
/* Removes awkward default styles on some inputs for iOS */
input[type="email"],
input[type="number"],
input[type="search"],
input[type="text"],
input[type="tel"],
input[type="url"],
input[type="password"],
textarea {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none; }
textarea {
  min-height: 65px;
  padding-top: 6px;
  padding-bottom: 6px; }
input[type="email"]:focus,
input[type="number"]:focus,
input[type="search"]:focus,
input[type="text"]:focus,
input[type="tel"]:focus,
input[type="url"]:focus,
input[type="password"]:focus,
textarea:focus,
select:focus {
  border: 1px solid #33C3F0;
  outline: 0; }
label,
legend {
  display: block;
  margin-bottom: .5rem;
  font-weight: 600; }
fieldset {
  padding: 0;
  border-width: 0; }
input[type="checkbox"],
input[type="radio"] {
  display: inline; }
label > .label-body {
  display: inline-block;
  margin-left: .5rem;
  font-weight: normal; }
ul {
  list-style: circle; }
ol {
  list-style: decimal; }
ul ul,
ul ol,
ol ol,
ol ul {
  margin: 1.5rem 0 1.5rem 3rem;
  font-size: 90%; }
li > p {margin : 0;}
th,
td {
  padding: 12px 15px;
  text-align: left;
  border-bottom: 1px solid #E1E1E1; }
th:first-child,
td:first-child {
  padding-left: 0; }
th:last-child,
td:last-child {
  padding-right: 0; }
button,
.button {
  margin-bottom: 1rem; }
input,
textarea,
select,
fieldset {
  margin-bottom: 1.5rem; }
pre,
blockquote,
dl,
figure,
table,
p,
ul,
ol,
form {
  margin-bottom: 1.0rem; }
.u-full-width {
  width: 100%;
  box-sizing: border-box; }
.u-max-full-width {
  max-width: 100%;
  box-sizing: border-box; }
.u-pull-right {
  float: right; }
.u-pull-left {
  float: left; }
hr {
  margin-top: 3rem;
  margin-bottom: 3.5rem;
  border-width: 0;
  border-top: 1px solid #E1E1E1; }
.container:after,
.row:after,
.u-cf {
  content: "";
  display: table;
  clear: both; }

pre {
  display: block;
  padding: 9.5px;
  margin: 0 0 10px;
  font-size: 13px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  border: 1px solid #ccc;
  border-radius: 4px;
}

pre.hljl {
  margin: 0 0 10px;
  display: block;
  background: #f5f5f5;
  border-radius: 4px;
  padding : 5px;
}

pre.output {
  background: #ffffff;
}

pre.code {
  background: #ffffff;
}

pre.julia-error {
  color : red
}

code,
kbd,
pre,
samp {
  font-family: Menlo, Monaco, Consolas, "Courier New", monospace;
  font-size: 13px;
}


@media (min-width: 400px) {}
@media (min-width: 550px) {}
@media (min-width: 750px) {}
@media (min-width: 1000px) {}
@media (min-width: 1200px) {}

h1.title {margin-top : 20px}
img {max-width : 100%}
div.title {text-align: center;}

  </style>



</HEAD>
  <BODY>
    <div class ="container">
      <div class = "row">
        <div class = "col-md-12 twelve columns">

          <div class="title">
            <h1 class="title">AR(p) auto-correlated trials with LMMs</h1>
            <h5>H. Matuschek</h5>
            <h5>2020-02-13</h5>
          </div>

          

<p>Frequently, the assumption of i.i.d. residuals is simply wrong. E.g., fitting LMMs to time-series data. It is reasonable to assume that there are at least some correlations present between consecutive observations within trials. Typical examples are EEG experiments or even the famous lme4::sleepstudy dataset.</p>
<p>A <em>normal</em> LMM describes data <span class="math">$\vec y$</span> in terms of a multivariate Gaussian distribution. That is,</p>
<p class="math">\[
\vec y|(\mathcal{B}=\vec b) \sim \mathcal{N}\left(X\,\vec\beta + Z\,\vec b, \sigma^2\mathbb{1}\right)\quad \text{with }
\mathcal{B} \sim \mathcal{N}\left(\vec 0, \Sigma_{\vec \theta}\right)\,,
\]</p>
<p>where <span class="math">$\vec\beta$</span> and <span class="math">$\vec b$</span> are the vectors of fixed and random effect coefficients, <span class="math">$F$</span> and <span class="math">$Z$</span> are the fixed and random effect system matrices respectively. Finally, <span class="math">$\Sigma_{\vec \theta}$</span> is the random effect covariance parameterized by the variance components in <span class="math">$\vec \theta$</span>.</p>
<p>Whenever there are within-trial correlations present, the unit-matrix &#40;<span class="math">$\mathbb{1}$</span>&#41; will turn into a correlation matrix <span class="math">$\Gamma_{\vec \theta}$</span> parameterized by some additional variance components in <span class="math">$\vec \theta$</span>. Thus an LMM describing correlated observations would change to</p>
<p class="math">\[
\vec y|(\mathcal{B}=\vec b) \sim \mathcal{N}\left(X\,\vec\beta + Z\,\vec b, \sigma^2\Gamma_{\vec \theta}\right)\quad \text{with }
\mathcal{B} \sim \mathcal{N}\left(\vec 0, \Sigma_{\vec \theta}\right)\,,
\]</p>
<p>Usually, <span class="math">$\Gamma$</span> will be relatively dense and of full rank. In numerical terms: it is an <em>expensive</em> matrix.</p>
<p><em>Pre-whitening</em>, now, is the black magic that turns the <span class="math">$\Gamma$</span>-matrix back into a unit matrix. That is, we search for a matrix <span class="math">$W_{\vec \theta}$</span> that we throw on the LMM and data</p>
<p class="math">\[
W_{\vec \theta}\,\vec y|(\mathcal{B}=\vec b) \sim \mathcal{N}\left(W_{\vec \theta}\,X\,\vec\beta +
  W_{\vec \theta}\,Z\,\vec b,
  \sigma^2W_{\vec \theta}\,\Gamma_{\vec \theta}\,W_{\vec \theta}^T\right)\quad \text{with }
\mathcal{B} \sim \mathcal{N}\left(\vec 0, \Sigma_{\vec \theta}\right)\,,
\]</p>
<p>such that <span class="math">$\mathbb{1} = W_{\vec \theta}\,\Gamma_{\vec \theta}\,W_{\vec \theta}^T$</span>. In fact this is quiet easy to do: The so-called Cholesky factorization <span class="math">$L\,L^T = \Gamma$</span> provides a lower-triangular matrix <span class="math">$L$</span> and with <span class="math">$W = L^{-1}$</span>, that is the inverse of <span class="math">$L$</span>, one can immediately turn <span class="math">$\Gamma$</span> back into a unit matrix <span class="math">$\mathbb{1} = L^{-1}\,\Gamma\,L^{-T}$</span>.</p>
<p>Depending on the underlying process, the covariance matrix <span class="math">$\Gamma$</span> or its Cholesky factor <span class="math">$L$</span> might be dense and irregularly structured. In these cases, the Cholesky decomposition and inversion of <span class="math">$L$</span> might be slow. However, in some cases there will be no other option to perform the pre-whitening by means of Cholesky factorization of the complete covariance matrix. For example whenever samples are taken irregularly of if samples are missing.</p>
<h1>Mathematical introduction</h1>
<p>Unsurprisingly, the covariance matrix <span class="math">$\Gamma$</span> cannot be obtained without any assumptions about the underlying process that generated these correlated samples. A frequent choice for such a random process are <em>auto-regressive</em> processes. A so-called auto-regressive process of order <span class="math">$p$</span> &#40;in short <span class="math">$AR(p)$</span>-process&#41; describes the time-series in terms of a linear combination of its own past of <span class="math">$p$</span> steps and some additive noise</p>
<p class="math">\[
 x_n = \phi_1\,x_{n-1} + \cdots + \phi_p\,x_{n-p} + \epsilon_n = \sum_{i=1}^p\phi_ix_{n-i}+\epsilon_n\,,
\]</p>
<p>where <span class="math">$E[\epsilon_n] = 0$</span> and <span class="math">$E[\epsilon_n\,\epsilon_m] = \sigma^2\delta_{n,m}$</span>.</p>
<p>The observed process is a convolution of noise with a filter-kernel <span class="math">$\phi_{-i}$</span>. The associated deconvolution/whitening operation can be expressed simply by subtracting the time-series with the weighted sum of its own past.</p>
<p class="math">\[
 \epsilon_n = x_n - \sum_{i=1}^p\phi_ix_{n-i}
\]</p>
<p>with <span class="math">$\phi_0=-1$</span>, one obtains</p>
<p class="math">\[
 \epsilon_n = -\sum_{i=0}^p\phi_i\,x_{n-i}\,.
\]</p>
<p>To this end, the de-convolution/whitening of the process is performed by a matrix <span class="math">$W_{n,i}$</span> of the form</p>
<p class="math">\[
 W_{n,i} = \begin{cases} 0 & i>n \\ 1 & i=n \\ -\phi_{n-i} & (n-p)\le i < n \\  0 & i < (n-p)\end{cases}
\]</p>
<p>This is a very sparse matrix containing only up to <span class="math">$p$</span> sub-diagonals&#33; To this end, using this sparse pre-whitening matrix would allow for an incredible fast pre-whitening of the data in <span class="math">$O(p\,n)$</span>, that is in linear time.</p>
<p>As a brief side note: Please observe that</p>
<p class="math">\[
 E[\epsilon_n\,\epsilon_m] = W_{n,i}\, \underbrace{E[x_i\,x_j]}_{: = \Gamma_{i,j}}\, \left(W_{m,j}\right)^T: =\sigma^2\mathbb{1}
\]</p>
<p>This leads directly to a problem whitening the first <span class="math">$p$</span> samples of a stationary <span class="math">$AR(p)$</span> process in steady-state. To derive the first whitened sample, the unobserved past <span class="math">$p-1$</span> samples must be known. That is,</p>
<p class="math">\[
 \epsilon_1 = x_1 - \underbrace{\sum_{i=1}^p \phi_i\,x_{1-i}}_{\text{unknown}}\,.
\]</p>
<p>Ignoring these contributions of the unobserved past will result in an pre-whitening under the implicit assumption that <span class="math">$x_{i}=0\,\forall i\le 0$</span>. This is almost never the case. Moreover, the covariance of the process <span class="math">$\Gamma$</span> was derived under the assumption of an stationary <span class="math">$AR(p)$</span>-process in steady-state. The implicit assumption of <span class="math">$x_{i}=0\,\forall i\le 0$</span> breaks the assumption of a steady state.</p>
<h1>Concrete Example <span class="math">$AR(1)$</span></h1>
<p>To demonstrate the issue, consider the explicit example of an <span class="math">$AR(1)$</span> process</p>
<p class="math">\[
 x_n = \phi x_{n-1} + \epsilon_n
\]</p>
<p>The whitening matrix <span class="math">$W$</span> would be</p>
<p class="math">\[
 W = \left(\begin{array}{cccccc}
   1 & 0 & 0 & 0 & \cdots & 0 \\
   -\phi & 1 & 0 & 0 &\cdots & 0 \\
   0 & -\phi & 1 & 0 &\cdots & 0 \\
   \vdots & & \ddots & \ddots &  & \vdots\\
   0 & \cdots & 0 & -\phi & 1 & 0 \\
   0 & 0 & \cdots & 0 & -\phi & 1
   \end{array}\right)
\]</p>
<p>Again, simply multiplying the vector of observations <span class="math">$\vec x$</span> on <span class="math">$W$</span> from the left would imply the assumption that <span class="math">$x_{0}=0$</span>.</p>
<p>Under the assumption of an stationary GP in steady state, the auto-correlation of the process is fully specifies by the auto-correlation function. For an <span class="math">$AR(1)$</span>-process with <span class="math">$0<\phi_1<1$</span> this auto-correlation can be obtained by means of the Yule-Walker equations as</p>
<p class="math">\[
 \rho(0) = 1,\quad \rho(n) = \phi\,\rho(n-1)\Rightarrow \rho(n) = \phi^n\,.
\]</p>
<p>With this, the covariance matrix of the process in steady-state can be obtained explicitly as a symmetric Toeplitz matrix</p>
<p class="math">\[
  \Gamma = \left(\begin{array}{ccccc}
   1 & \phi & \phi^2 & \phi^3 &  \\
   \phi & 1 & \phi & \phi^2 & \ddots  \\
   \phi^2 & \phi & 1 & \phi & \ddots  \\
   \phi^3 & \phi^2 & \phi & 1 & \ddots  \\
   & \ddots &  \ddots & \ddots & \ddots
   \end{array}\right)
\]</p>
<p>With the relation observed above, one should find</p>
<p class="math">\[
 \mathbb 1_{n,m} = W_{n,i}\,\Gamma_{i,j}\left(W_{m,j}\right)^T
\]</p>


<pre class='hljl'>
<span class='hljl-n'>ϕ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>]</span><span class='hljl-t'>
</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>W</span><span class='hljl-p'>(</span><span class='hljl-ni'>5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ϕ</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-kc'>false</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>Γ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Γ_ar</span><span class='hljl-p'>(</span><span class='hljl-ni'>5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ϕ</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-n'>E</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>Symmetric</span><span class='hljl-p'>(</span><span class='hljl-nf'>BandedMatrix</span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>Γ</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>transpose</span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>ϕ</span><span class='hljl-p'>),</span><span class='hljl-nf'>length</span><span class='hljl-p'>(</span><span class='hljl-n'>ϕ</span><span class='hljl-p'>))))</span><span class='hljl-t'>
</span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>-&gt;</span><span class='hljl-nf'>round</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>digits</span><span class='hljl-oB'>=</span><span class='hljl-ni'>2</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>E</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
5×5 Array&#123;Float64,2&#125;:
 0.5  0.0   0.0   0.0   0.0 
 0.0  0.38  0.0   0.0   0.0 
 0.0  0.0   0.38  0.0   0.0 
 0.0  0.0   0.0   0.38  0.0 
 0.0  0.0   0.0   0.0   0.38
</pre>


<p>Obviously, this is not the case. These <em>mistakes</em>, however, are limited to a band with band-width equal to the order of the process <span class="math">$p$</span>. This relatively sparse matrix can then be factored and used to <em>update</em> the whitening matrix <span class="math">$F$</span>.</p>


<pre class='hljl'>
<span class='hljl-n'>E</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>cholesky</span><span class='hljl-p'>(</span><span class='hljl-n'>E</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-n'>wc</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-n'>E</span><span class='hljl-oB'>.</span><span class='hljl-n'>L</span><span class='hljl-t'> </span><span class='hljl-oB'>\</span><span class='hljl-t'> </span><span class='hljl-nf'>Matrix</span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-p'>);</span><span class='hljl-t'>
</span><span class='hljl-nf'>map</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-oB'>-&gt;</span><span class='hljl-nf'>round</span><span class='hljl-p'>(</span><span class='hljl-n'>x</span><span class='hljl-p'>,</span><span class='hljl-n'>digits</span><span class='hljl-oB'>=</span><span class='hljl-ni'>5</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>wc</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>Γ</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>transpose</span><span class='hljl-p'>(</span><span class='hljl-n'>wc</span><span class='hljl-p'>))</span>
</pre>


<pre class="output">
5×5 Array&#123;Float64,2&#125;:
 1.0  -0.0  -0.0  -0.0  -0.0
 0.0   1.0   0.0   0.0   0.0
 0.0   0.0   1.0   0.0   0.0
 0.0   0.0   0.0   1.0   0.0
 0.0   0.0   0.0   0.0   1.0
</pre>


<p>This Cholesky decomposition differs from the decomposition of the covariance matrix <span class="math">$\Gamma$</span>. While the covariance matrix is frequently dense, the <em>error</em> matrix <span class="math">$E$</span> here is banded matrix with band-width of max. <span class="math">$p$</span>. This allows for a very efficient decomposition. In fact the asymptotic complexity of this Cholesky decomposition is <span class="math">$O(n\,p^2)$</span> and thus linear in the number of samples. This scales much better compared to <span class="math">$O(n^3)$</span> for a decomposition of an arbitrary symmetric dense <span class="math">$\Gamma$</span> and even better than the complexity <span class="math">$O(n^2)$</span> of performing the decomposition of a Toeplitz matrix as it would arise in case of a <span class="math">$AR(p)$</span> process.</p>
<p>This correction is implemented inside the <span class="math">$W()$</span>-function when the <em>stationary</em> argument is set to true &#40;default&#41;. Thus</p>


<pre class='hljl'>
<span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>W</span><span class='hljl-p'>(</span><span class='hljl-ni'>5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ϕ</span><span class='hljl-p'>)</span><span class='hljl-t'>
</span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-n'>Γ</span><span class='hljl-t'> </span><span class='hljl-oB'>*</span><span class='hljl-t'> </span><span class='hljl-nf'>transpose</span><span class='hljl-p'>(</span><span class='hljl-n'>w</span><span class='hljl-p'>))</span>
</pre>


<pre class="output">
5×5 Array&#123;Float64,2&#125;:
 1.0  0.0  0.0  0.0  0.0
 0.0  1.0  0.0  0.0  0.0
 0.0  0.0  1.0  0.0  0.0
 0.0  0.0  0.0  1.0  0.0
 0.0  0.0  0.0  0.0  1.0
</pre>


<p>yields the correct whitening matrix immediately.</p>
<h2>Brief example for an <span class="math">$AR(3)$</span></h2>
<p>Given the coefficents <span class="math">$\vec \phi$</span> for an <span class="math">$AR(3)$</span> process, the whitening matrix <span class="math">$W$</span> is obtained using the <span class="math">$W()$</span> function</p>


<pre class='hljl'>
<span class='hljl-n'>ϕ</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-p'>[</span><span class='hljl-nfB'>0.5</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-oB'>-</span><span class='hljl-nfB'>0.25</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-nfB'>0.1</span><span class='hljl-p'>];</span><span class='hljl-t'>
</span><span class='hljl-cs'># get uncorrected whitening matrix</span><span class='hljl-t'>
</span><span class='hljl-n'>w</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nf'>W</span><span class='hljl-p'>(</span><span class='hljl-ni'>10</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>ϕ</span><span class='hljl-p'>)</span>
</pre>


<pre class="output">
10×10 BandedMatrices.BandedMatrix&#123;Float64,Array&#123;Float64,2&#125;,Base.OneTo&#123;Int64
&#125;&#125;:
  1.5828       ⋅           ⋅         …   ⋅          ⋅          ⋅     
  0.0416671   1.58335      ⋅             ⋅          ⋅          ⋅     
  0.0211132   0.0422264   1.58349        ⋅          ⋅          ⋅     
 -0.158604    0.0169894   0.040323       ⋅          ⋅          ⋅     
   ⋅         -0.161129    0.0160585      ⋅          ⋅          ⋅     
   ⋅           ⋅         -0.161201   …   ⋅          ⋅          ⋅     
   ⋅           ⋅           ⋅             ⋅          ⋅          ⋅     
   ⋅           ⋅           ⋅            1.59412     ⋅          ⋅     
   ⋅           ⋅           ⋅            0.049802   1.59412     ⋅     
   ⋅           ⋅           ⋅            0.0156307  0.0497999  1.59412
</pre>


<p>This is again a lower-banded matrix where there are at most <span class="math">$p$</span> sub-diagonals. And multiplying this sparse matrix to the observations as well as to the entire model will not increase the computational costs significantly.</p>
<h1>Possible UI</h1>
<p>There are basically two ways one could extend the formula syntax.</p>
<p>The first would mimic an additional <em>random effect</em>, although it is not implemented as one:</p>



<pre class='hljl'>
<span class='hljl-n'>f</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'> </span><span class='hljl-nd'>@formula</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>+</span><span class='hljl-n'>B</span><span class='hljl-oB'>|</span><span class='hljl-n'>Subj</span><span class='hljl-p'>)</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-nf'>AR</span><span class='hljl-p'>(</span><span class='hljl-n'>p</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>t</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Subj</span><span class='hljl-oB'>/</span><span class='hljl-n'>Trial</span><span class='hljl-p'>)</span>
</pre>


<p>This form might be the easiest way to implement pre-whitening into the existing formula macro.</p>
<p>Although, a more mathematically correct form could be</p>



<pre class='hljl'>
<span class='hljl-n'>f</span><span class='hljl-t'> </span><span class='hljl-oB'>=</span><span class='hljl-t'>  </span><span class='hljl-nd'>@formula</span><span class='hljl-t'> </span><span class='hljl-nf'>AR</span><span class='hljl-p'>(</span><span class='hljl-ni'>2</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>y</span><span class='hljl-t'> </span><span class='hljl-oB'>~</span><span class='hljl-t'> </span><span class='hljl-ni'>1</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-n'>A</span><span class='hljl-t'> </span><span class='hljl-oB'>+</span><span class='hljl-t'> </span><span class='hljl-p'>(</span><span class='hljl-ni'>1</span><span class='hljl-oB'>+</span><span class='hljl-n'>B</span><span class='hljl-oB'>|</span><span class='hljl-n'>Subj</span><span class='hljl-p'>),</span><span class='hljl-t'> </span><span class='hljl-n'>t</span><span class='hljl-p'>,</span><span class='hljl-t'> </span><span class='hljl-n'>Subj</span><span class='hljl-oB'>/</span><span class='hljl-n'>Trial</span><span class='hljl-p'>)</span>
</pre>


<p>the latter, however is would break the current implementation of the formula macro and is harder to read.</p>



          <HR/>
          <div class="footer"><p>
          Published from <a href="ar.jmd">ar.jmd</a> using
          <a href="http://github.com/mpastell/Weave.jl">Weave.jl</a>
           on 2020-02-18.
          <p></div>


        </div>
      </div>
    </div>
  </BODY>
</HTML>
